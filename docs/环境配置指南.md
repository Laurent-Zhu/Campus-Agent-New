# 🛠️ 教学实训智能体系统环境配置指南

## 1. 系统要求

- Python 3.10+
- 至少 8GB RAM
- 50GB 磁盘空间(用于模型存储)
- CUDA 支持(可选,用于GPU加速)

## 2. 目录结构创建

```bash
mkdir -p campus-agent/{frontend,backend,ai_agents,models,knowledge,data,visualize,config}
cd campus-agent
```

## 3. Python 环境配置

```bash
# 创建并激活虚拟环境
conda create -n campus-agent python=3.10
conda activate campus-agent

# 克隆项目(如果是从Git仓库)
git clone https://github.com/your-repo/campus-agent.git
cd campus-agent
```

## 4. 依赖包安装

```bash
# 核心依赖
pip install langchain==0.1.0         # LangChain框架
pip install fastapi==0.104.1         # 后端API框架
pip install uvicorn==0.24.0          # ASGI服务器
pip install pydantic==2.5.2          # 数据验证
pip install transformers==4.35.2     # Transformers库
pip install torch==2.1.1             # PyTorch
pip install chromadb==0.4.18         # 向量数据库
pip install python-jose==3.3.0       # JWT认证
pip install python-multipart==0.0.6  # 文件上传
pip install sqlalchemy==2.0.23       # ORM框架

# 文档处理相关
pip install unstructured           # 文档解析
pip install pymupdf               # PDF处理
pip install python-docx           # Word文档处理

# 可视化相关
pip install streamlit             # 数据可视化
pip install plotly               # 交互式图表
pip install echarts-python       # Echarts图表
```

## 5. 模型下载与配置

```bash
# 1. 创建模型目录
mkdir -p models/llm
cd models/llm

# 2. 安装git-lfs
sudo apt-get install git-lfs
git lfs install

# 3. 从HuggingFace下载模型(二选一)

# 方式1：直接克隆(推荐，但需要较好的网络环境)
git clone https://huggingface.co/THUDM/chatglm3-6b
# 方式1-1：使用镜像站
export HF_ENDPOINT=https://hf-mirror.com
git clone https://hf-mirror.com/THUDM/chatglm3-6b

# 方式2：使用huggingface_hub下载(可断点续传)
pip install --upgrade huggingface_hub
python -c "from huggingface_hub import snapshot_download; snapshot_download(repo_id='THUDM/chatglm3-6b', local_dir='./chatglm3-6b')"

# 如果下载速度较慢，可以设置国内镜像
export HF_ENDPOINT=https://hf-mirror.com
```

如果遇到网络问题，也可以：
1. 使用代理
2. 从国内镜像站下载
3. 使用离线模型包

## 6. 环境变量配置

创建 `.env` 文件:

```env
# 模型配置
MODEL_PATH=/home/laurentzhu/PycharmProjects/CampusAgent/campus-agent/models/llm/chatglm3-6b
DEVICE=cuda  # 如果没有GPU，请改为cpu

# 数据库配置
DB_URL=sqlite:////home/laurentzhu/PycharmProjects/CampusAgent/campus-agent/campus_agent.db
DB_ECHO=True  # 开发环境打印SQL语句

# 安全配置
JWT_SECRET_KEY=$(openssl rand -hex 32)  # 生成随机密钥
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
CORS_ORIGINS=["http://localhost:3000","http://127.0.0.1:3000"]

# 文件存储
UPLOAD_DIR=/home/laurentzhu/PycharmProjects/CampusAgent/campus-agent/data/uploads
VECTOR_DB_PATH=/home/laurentzhu/PycharmProjects/CampusAgent/campus-agent/data/vector_store
MAX_UPLOAD_SIZE=10485760  # 10MB

# 日志配置
LOG_LEVEL=DEBUG
LOG_FILE=/home/laurentzhu/PycharmProjects/CampusAgent/campus-agent/logs/app.log
```

## 7. 数据库初始化

```bash
# 创建数据库迁移
alembic init migrations

# 生成迁移脚本
alembic revision --autogenerate -m "initial"

# 执行迁移
alembic upgrade head
```

## 8. 启动服务

```bash
# 后端服务
uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000

# 前端开发服务器(新终端)
cd frontend
npm install
npm run dev
```

## 9. 验证部署

访问以下地址验证服务是否正常运行：
- Swagger API文档: http://localhost:8000/docs
- 前端界面: http://localhost:3000

## 10. 开发工具推荐

- IDE: VSCode
  - Python 插件
  - Pylance
  - GitLens
  - Vue Language Features
  - Auto Docstring

## 11. 常见问题处理

### CUDA 相关
```bash
# 检查CUDA是否可用
python -c "import torch; print(torch.cuda.is_available())"

# 查看CUDA版本
nvidia-smi
```

### 依赖问题
```bash
# 清理pip缓存
pip cache purge

# 导出依赖
pip freeze > requirements.txt

# 从requirements.txt安装
pip install -r requirements.txt
```

### 数据库问题
```bash
# 重置数据库
alembic downgrade base
alembic upgrade head

# 备份数据库
sqlite3 campus.db ".backup 'backup.db'"
```

### 内存问题
```bash
# Linux查看内存使用
free -h

# 清理显存
torch.cuda.empty_cache()
```